local Network_SA = require 'Network_SpeakerAdaption'
local cmd = torch.CmdLine()
io.stdout:setvbuf("no")
-- Options can be overrided on command line run.
cmd:option('-loadModel',true, 'Load previously saved model')
cmd:option('-saveModel', true, 'Save model after training/testing')
cmd:option('-modelName', 'DeepSpeechModel', 'Name of class containing architecture')
cmd:option('-nGPU', 1, 'Number of GPUs, set -1 to use CPU')
cmd:option('-trainingSetLMDBPath','./merge_ds_norm/F01/train_test_split/lmdb/train_aug/', 'Path to LMDB training dataset')
cmd:option('-validationSetLMDBPath','./merge_ds_norm/F03/lmdb/val/', 'Path to LMDB test dataset')
cmd:option('-logsTrainPath', './logs/TrainingLoss/')
cmd:option('-logsValidationPath', './logs/ValidationScores/', ' Path to save Validation logs')
cmd:option('-saveModelInTraining', true, 'save model periodically through training')
cmd:option('-modelTrainingPath', './new_1000_hrs_model/', ' Path to save periodic training models')
cmd:option('-saveModelIterations', 10, 'When to save model through training')
cmd:option('-modelPath','model_epoch_2_20170326_130052_best_model_libri_deepspeech.t7','Path to save model')
cmd:option('-dictionaryPath', './dictionary', ' File containing the dictionary to use')
cmd:option('-epochs', 20, 'Number of epochs for training')
cmd:option('-learningRate', 3e-4, ' Training learning rate')
cmd:option('-learningRateAnnealing', 1.1, 'Factor to anneal lr every epoch')
cmd:option('-maxNorm', 100, 'Max norm used to normalize gradients')
cmd:option('-momentum', 0.90, 'Momentum for SGD')
cmd:option('-batchSize', 10, 'Batch size in training')
cmd:option('-validationBatchSize', 10, 'Batch size for validation')
cmd:option('-hiddenSize', 1760, 'RNN hidden sizes')
cmd:option('-nbOfHiddenLayers', 7, 'Number of rnn layers')
cmd:option('-dropout',0,'apply dropout')
cmd:option('-adaptLayers',1,'No of layers to adapt')
cmd:option('-adaptLayerLearningRate',0.001,'Learning rate for Linear Unit contribution layer')
cmd:option('-saveProbMatrix','./predictionMatrix/','To save probability matrix for character language model')
local opt = cmd:parse(arg)
--Create and train the network based on the parameters and training data.
Network_SA:init(opt)
Network_SA:trainNetwork(opt.epochs, opt)